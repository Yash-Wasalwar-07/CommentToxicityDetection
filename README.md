# CommentToxicityDetection

In this project, we will be building a NLP application using Gradio which can identify a comment/sentence as toxic or not.
There are various levels of toxicity and some of them which are in this project are as follows:

1. Toxic 
2. Severe Toxic
3. Obscene
4. Threat
5. Insult
6. Identity hate

Let's look at some example sentences :
